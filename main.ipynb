{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:OutfitDataset - itemIdentifier2ItemId's 1st 10 items: {'224930161_1': '213343990', '224930161_2': '206270853', '224930161_3': '202059322', '224930161_4': '53908391', '208756998_1': '182121462', '208756998_2': '184300769', '208756998_3': '185818820', '208756998_4': '185817365', '208756998_5': '185818053', '218698690_1': '206948767'}\n",
      "DEBUG:root:imageNames 1st 10 items: ['202321215', '200886508', '209234827', '148482437', '208219955', '52192148', '163215721', '187916901', '159655041', '33446168']\n",
      "DEBUG:root:OutfitDataset - itemIdToIndex's 1st 10 items: {'202321215': 0, '200886508': 1, '209234827': 2, '148482437': 3, '208219955': 4, '52192148': 5, '163215721': 6, '187916901': 7, '159655041': 8, '33446168': 9}\n",
      "DEBUG:root:OutfitDataset - itemIdToDescription's 1st 10 items: {'202321215': 'saint laurent pink medium monogram', '200886508': 'h&m leather trousers', '209234827': 'steve madden baddison handbag backpack', '148482437': 'bloomingdales cashmere ribbed gloves', '208219955': 'marco de vincenzo fringed milano', '52192148': 'manhattan pearls white graduated pearl', '163215721': 'shein sheinside black buckle pu', '187916901': 'metal tassels acrylic evening bag', '159655041': 'versus versace lion head piercing', '33446168': 'enamel flower with pave center'}\n",
      "DEBUG:root:OutfitDataset - compatibility_questions's 1st 10 items: [(['213343990', '206270853', '202059322', '53908391'], 1), (['182121462', '184300769', '185818820', '185817365', '185818053'], 1), (['206948767', '202252504', '191102174', '146065668', '183483401', '178982870', '198760643', '194076684'], 1), (['174026597', '157770232', '135330127', '172140335', '172753329'], 1), (['177476594', '179318317', '169982065', '174520319', '171526545', '174662809'], 1), (['202343318', '202343187', '202343207', '193478849', '197101949', '202342799', '202191391'], 1), (['178420951', '170554032', '178376577', '173329218', '170606210', '173099588'], 1), (['192578785', '187607590', '156237229', '187719795', '191407280', '154546907', '128993650', '173572283', '191792933', '192581760', '184584032'], 1), (['165029012', '202349064', '49885098'], 1), (['206337991', '210454684', '202054602', '192628622', '209092995', '8831337', '201914213'], 1)]\n",
      "DEBUG:root:OutfitDataset - outfit_images.shape: torch.Size([4, 3, 224, 224]), items_descriptions: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MockOutfitDataset; images: torch.Size([20, 5, 3, 224, 224]), texts: [['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4'], ['mock description 0', 'mock description 1', 'mock description 2', 'mock description 3', 'mock description 4']]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from focal_loss import FocalLoss\n",
    "from mock_dataset import MockOutfitDataset\n",
    "from outfit_model import OutfitCompatibilityModel\n",
    "from outfit_dataset import OutfitDataset\n",
    "import torch.nn as nn\n",
    "from utils import save_checkpoint\n",
    "import logging\n",
    "\n",
    "# DEBUG - INFO - WARNING - ERROR\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Should be disjoint/nondisjoint\n",
    "polyvore_split = \"nondisjoint\"\n",
    "\n",
    "# Should be traim/valid/test\n",
    "split = \"valid\"\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Organizes your dataset into batches. If we don't do this, our texts matrix will be transposed\n",
    "# Batch size = number of samples processed in one iteration\n",
    "# Number of batches = total samples divided by batch_size\n",
    "# Each this case, a sample = an outfit\n",
    "def custom_collate(batch):\n",
    "    outfits_images = []\n",
    "    outfits_texts = []\n",
    "    outfits_labels = []\n",
    "\n",
    "    # Find the maximum number of items in any outfit in this batch\n",
    "    max_items = max(len(outfit[\"outfit_images\"]) for outfit in batch)\n",
    "\n",
    "    for outfit in batch:\n",
    "        # Pad or truncate the number of items to match max_items\n",
    "        padded_images = torch.zeros((max_items,) + outfit[\"outfit_images\"].shape[1:])\n",
    "        padded_images[: outfit[\"outfit_images\"].shape[0]] = outfit[\"outfit_images\"]\n",
    "\n",
    "        # Similarly, pad or truncate the number of texts\n",
    "        padded_texts = outfit[\"outfit_texts\"] + [\"\"] * (\n",
    "            max_items - len(outfit[\"outfit_texts\"])\n",
    "        )\n",
    "\n",
    "        outfits_images.append(padded_images)\n",
    "        outfits_texts.append(padded_texts)\n",
    "        outfits_labels.append(outfit[\"outfit_label\"])\n",
    "\n",
    "    return {\n",
    "        \"outfit_images\": torch.stack(outfits_images),\n",
    "        \"outfit_texts\": outfits_texts,\n",
    "        \"outfit_labels\": torch.tensor(outfits_labels, dtype=torch.float),\n",
    "    }\n",
    "\n",
    "\n",
    "real_dataset = OutfitDataset(data_dir, polyvore_split, split, transform)\n",
    "real_dataloader = torch.utils.data.DataLoader(\n",
    "    real_dataset, batch_size=5, shuffle=True, collate_fn=custom_collate\n",
    ")\n",
    "\n",
    "# Instantiate the mock dataset and dataloader\n",
    "# Contains list of all outfits\n",
    "mock_dataset = MockOutfitDataset()\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    mock_dataset, batch_size=15, shuffle=True, collate_fn=custom_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NOT USABLE\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "# def show_images(images, labels):\n",
    "#     for i in range(images.size(1)):\n",
    "#         image = F.to_pil_image(images[:, i, ...])\n",
    "#         plt.subplot(1, images.size(1), i + 1)\n",
    "#         plt.imshow(image)\n",
    "#         plt.title(f\"Label: {labels[i]}\")\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# for batch_idx, (images, texts, labels) in enumerate(dataloader):\n",
    "#     print(\n",
    "#         f\"Batch {batch_idx + 1} - Shape of images: {images.shape}, Texts: {texts}, Labels: {labels}\"\n",
    "#     )\n",
    "\n",
    "#     # Visualize the images\n",
    "#     show_images(images, labels)\n",
    "    \n",
    "#     if batch_idx == 2:  # Print information for the first 3 batches\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/bert-base-nli-mean-tokens/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /sentence-transformers/bert-base-nli-mean-tokens/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "c:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and components for training (loss function, optimizer)\n",
    "model = OutfitCompatibilityModel()\n",
    "focal_loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:!!!!!!!!!!\n",
      "DEBUG:root:OutfitCompatibilityModel - START\n",
      "DEBUG:root:OutfitCompatibilityModel - intial images.shape: torch.Size([5, 7, 3, 224, 224])\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:[START LOOP] OUTFIT - 0\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_images.shape: torch.Size([7, 3, 224, 224])\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 0\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 0 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: push lock cross body sequin\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch - images.shape: torch.Size([5, 7, 3, 224, 224])\n",
      "batch - texts: [['push lock cross body sequin', 'glitter stiletto heel peep toe', 'glitter mini heel peep toe', 'gurhan small 24k gold amulet', 'signature gold heart bracelet in', 'feather print fit flare mini', 'philosophy di lorenzo serafini mink'], ['burberry leather bowling bag', 'zara studded cowboy ankle boot', 'kain classic modal and silk-blend tank', 'h&m shirt', 'patek philippe gold automatic watch', 'illesteva leonard round-frame matte-acetate sunglasses', 'ted baker whistel - dark rinse skinny denim'], ['mini borsa metropolis in tessuto', 'alberta ferretti denim beaded mules', 'womens helene berman denim ruffle', \"marques'almeida denim tank top\", 'fendi womens ff0177 sunglasses', 'bliss and mischief shadow flower-embroidered denim shorts', ''], ['rebecca minkoff julian backpack with', 'adidas originals stan smith crackled leather sneakers - white/navy', 'stone black gold white diamonds', 'yohji yamamoto regular shirt', 'mango skinny paty jeans , black', 'alexander wang satin bomber jacket', ''], ['cult gaia mini acrylic ark', 'dsquared2 leather sandals', '25 off sale lampwork glass', '25 off sale terracotta lampwork', 'anna october cotton asymmetrical tie-front top', 'beautiful vintage ted lapidus paris', 'isabel marant Étoile oscar tie-waist cotton shorts']]\n",
      "batch - labels: tensor([1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 0\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 1\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 1 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: glitter stiletto heel peep toe\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 1\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 2\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 2 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: glitter mini heel peep toe\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 2\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 3\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 3 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: gurhan small 24k gold amulet\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 3\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 4\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 4 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: signature gold heart bracelet in\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 4\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 5\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 5 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: feather print fit flare mini\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 5\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 6\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 6 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: philosophy di lorenzo serafini mink\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 6\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:OutfitCompatibilityModel - curren outfit's feature vectors dimensions: 1 with lengths: [7]\n",
      "DEBUG:root:OutfitCompatibilityModel - CUR OUTFIT's feature vectors after stack: torch.Size([1, 7, 128])\n",
      "DEBUG:root:[END LOOP] OUTFIT - 0\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:[START LOOP] OUTFIT - 1\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_images.shape: torch.Size([7, 3, 224, 224])\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 0\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 0 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: burberry leather bowling bag\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 0\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 1\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 1 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: zara studded cowboy ankle boot\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 1\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 2\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 2 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: kain classic modal and silk-blend tank\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 2\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 3\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 3 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: h&m shirt\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 3\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 4\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 4 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: patek philippe gold automatic watch\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 4\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 5\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 5 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: illesteva leonard round-frame matte-acetate sunglasses\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 5\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 6\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 6 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: ted baker whistel - dark rinse skinny denim\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 6\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:OutfitCompatibilityModel - curren outfit's feature vectors dimensions: 1 with lengths: [7]\n",
      "DEBUG:root:OutfitCompatibilityModel - CUR OUTFIT's feature vectors after stack: torch.Size([1, 7, 128])\n",
      "DEBUG:root:[END LOOP] OUTFIT - 1\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:[START LOOP] OUTFIT - 2\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_images.shape: torch.Size([7, 3, 224, 224])\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 0\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 0 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: mini borsa metropolis in tessuto\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 0\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 1\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 1 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: alberta ferretti denim beaded mules\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 1\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 2\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 2 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: womens helene berman denim ruffle\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 2\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 3\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 3 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: marques'almeida denim tank top\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 3\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 4\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 4 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: fendi womens ff0177 sunglasses\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 4\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 5\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 5 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: bliss and mischief shadow flower-embroidered denim shorts\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 5\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 6\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 6 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: \n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 6\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:OutfitCompatibilityModel - curren outfit's feature vectors dimensions: 1 with lengths: [7]\n",
      "DEBUG:root:OutfitCompatibilityModel - CUR OUTFIT's feature vectors after stack: torch.Size([1, 7, 128])\n",
      "DEBUG:root:[END LOOP] OUTFIT - 2\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:[START LOOP] OUTFIT - 3\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_images.shape: torch.Size([7, 3, 224, 224])\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 0\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 0 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: rebecca minkoff julian backpack with\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 0\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 1\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 1 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: adidas originals stan smith crackled leather sneakers - white/navy\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 1\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 2\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 2 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: stone black gold white diamonds\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 2\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 3\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 3 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: yohji yamamoto regular shirt\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 3\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 4\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 4 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: mango skinny paty jeans , black\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 4\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 5\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 5 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: alexander wang satin bomber jacket\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 5\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 6\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 6 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: \n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 6\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:OutfitCompatibilityModel - curren outfit's feature vectors dimensions: 1 with lengths: [7]\n",
      "DEBUG:root:OutfitCompatibilityModel - CUR OUTFIT's feature vectors after stack: torch.Size([1, 7, 128])\n",
      "DEBUG:root:[END LOOP] OUTFIT - 3\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:[START LOOP] OUTFIT - 4\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_images.shape: torch.Size([7, 3, 224, 224])\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 0\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 0 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: cult gaia mini acrylic ark\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 0\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 1\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 1 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: dsquared2 leather sandals\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 1\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 2\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 2 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: 25 off sale lampwork glass\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 2\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 3\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 3 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: 25 off sale terracotta lampwork\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 3\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 4\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 4 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: anna october cotton asymmetrical tie-front top\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 4\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 5\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 5 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: beautiful vintage ted lapidus paris\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 5\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:[START LOOP] ITEM - 6\n",
      "DEBUG:root:OutfitCompatibilityModel - item_index: 6 - item_image.shape: torch.Size([1, 3, 224, 224]) item_text.shape: isabel marant Étoile oscar tie-waist cotton shorts\n",
      "DEBUG:root:ImageEncoder - after fc_layer x's shape: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:TextEncoder - x's shape after fc_layer: torch.Size([1, 64])\n",
      "DEBUG:root:----------\n",
      "DEBUG:root:OutfitCompatibilityModel - item_features.shape: torch.Size([1, 128])\n",
      "DEBUG:root:[END LOOP] ITEM - 6\n",
      "DEBUG:root:##########\n",
      "DEBUG:root:OutfitCompatibilityModel - curren outfit's feature vectors dimensions: 1 with lengths: [7]\n",
      "DEBUG:root:OutfitCompatibilityModel - CUR OUTFIT's feature vectors after stack: torch.Size([1, 7, 128])\n",
      "DEBUG:root:[END LOOP] OUTFIT - 4\n",
      "DEBUG:root:@@@@@@@@@@\n",
      "DEBUG:root:OutfitCompatibilityModel - ALL OUTFITS' feature vetors: torch.Size([5, 7, 128])\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_token.shape - init: torch.Size([1, 1, 128])\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_token.shape - after expand: torch.Size([1, 1, 128])\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_features.shape: torch.Size([5, 8, 128])\n",
      "DEBUG:root:OutfitCompatibilityModel - transformer_output.shape: torch.Size([5, 8, 128])\n",
      "DEBUG:root:OutfitCompatibilityModel - global_outfit_representation: tensor([[-9.7455e-02,  2.3193e-01,  1.1904e+00,  3.2004e-01, -3.7540e-01,\n",
      "         -1.1228e-01, -3.6401e-01, -2.8798e-01, -8.0743e-01, -1.1197e+00,\n",
      "         -1.1820e-01, -1.5452e+00,  5.4147e-01, -5.5642e-01,  7.8086e-01,\n",
      "         -7.7961e-02, -1.6991e+00,  1.0110e-01,  7.4575e-01,  6.1460e-01,\n",
      "          6.4495e-01, -2.6831e-01, -5.9216e-01, -1.4079e-01, -8.4076e-01,\n",
      "          1.2543e+00,  6.2579e-01,  1.2099e+00, -3.4993e-01,  1.2021e+00,\n",
      "          1.4896e+00, -1.1257e-01,  1.6544e+00,  7.5960e-02,  3.1488e-01,\n",
      "         -2.3957e+00, -5.6617e-01,  9.1266e-01, -5.1917e-01,  3.7564e-01,\n",
      "          2.1977e+00, -2.2207e+00, -1.9142e-01, -8.1602e-01, -3.0750e-01,\n",
      "          2.1667e+00, -3.8624e-01,  2.0341e-01,  2.1036e-01,  8.1440e-01,\n",
      "         -8.2765e-01, -7.0937e-01,  1.1001e+00,  2.4645e-01,  1.0812e+00,\n",
      "          4.1297e-02,  1.4263e-01, -4.9086e-04,  1.0043e-01, -3.2159e-01,\n",
      "         -4.5737e-01, -1.0445e+00, -7.2449e-01, -9.6868e-01, -1.1153e-01,\n",
      "         -4.7141e-01, -3.2958e-01,  2.6509e-01, -9.9655e-02,  1.3717e+00,\n",
      "         -8.3773e-02,  1.4193e+00,  3.9796e-01,  4.7475e-01,  7.8837e-01,\n",
      "          7.6578e-01,  5.7916e-01,  4.2819e-01, -8.0514e-01, -1.6969e-01,\n",
      "          3.7482e-01,  8.0781e-01, -9.9502e-01,  8.7223e-02,  8.1652e-01,\n",
      "          2.2325e-01, -1.5474e-01,  8.4023e-01, -1.2868e+00, -1.8974e+00,\n",
      "         -8.9993e-01,  1.0370e+00, -1.5636e+00, -1.0578e+00, -1.7549e+00,\n",
      "         -5.5430e-01,  1.5004e+00, -7.5553e-01,  4.3268e-01, -4.5621e-01,\n",
      "          1.0812e+00,  6.1167e-01, -3.9948e-01, -6.1488e-02,  7.5801e-01,\n",
      "         -2.8618e-01, -6.4910e-01, -6.0129e-01,  6.4892e-01,  9.3820e-02,\n",
      "          2.2077e+00, -1.6099e+00, -1.4338e+00, -1.4601e-03, -1.9904e+00,\n",
      "         -2.1029e-01, -1.4687e-02, -7.2771e-01,  1.5792e+00,  4.4253e-01,\n",
      "         -6.6802e-01,  7.3661e-01,  1.3098e+00, -4.9617e-01, -6.5843e-03,\n",
      "          2.5380e-01, -3.4176e-01, -5.6273e-02],\n",
      "        [-4.4548e-01,  3.0221e-01,  1.2607e+00,  3.4163e-01, -2.8925e-01,\n",
      "         -2.2707e-01, -2.3169e-01,  2.6439e-01, -6.6790e-01, -1.2372e+00,\n",
      "         -3.2324e-01, -1.5935e+00,  1.0271e+00, -1.1292e+00,  1.8654e-01,\n",
      "          1.4598e-01, -2.0946e+00,  3.9038e-01,  1.0768e+00,  8.0134e-01,\n",
      "          3.8854e-01, -2.2661e-01, -4.3715e-01, -3.6387e-01, -3.8407e-01,\n",
      "          1.3708e+00,  2.4788e-01,  7.3337e-01, -8.9591e-02,  1.7749e+00,\n",
      "          2.7739e-01, -4.8382e-01,  1.4693e+00, -2.0011e-01,  7.3084e-01,\n",
      "         -2.7804e+00, -1.0695e-01,  1.0430e+00, -8.7802e-02,  5.8827e-01,\n",
      "          2.2104e+00, -1.8560e+00, -4.6742e-01, -4.8812e-01, -4.3520e-02,\n",
      "          2.2277e+00, -4.5224e-01,  2.8375e-01,  2.3382e-01,  7.1361e-01,\n",
      "         -1.7588e-01, -9.9185e-01,  1.0044e+00,  3.1859e-01,  1.6009e+00,\n",
      "         -2.0899e-01, -5.3792e-01, -1.7445e-01, -3.9387e-01, -4.5423e-01,\n",
      "         -1.7064e-01, -5.1117e-01, -1.2562e+00, -1.3399e+00,  1.8310e-01,\n",
      "          1.3814e-01,  5.9335e-01,  2.0010e-01, -5.0920e-01,  1.4816e+00,\n",
      "          4.2244e-01,  1.4426e+00,  8.4935e-01,  7.4423e-01,  7.3068e-01,\n",
      "          3.2495e-01,  7.2111e-01,  8.8272e-01, -4.8753e-01, -3.3551e-03,\n",
      "          5.2662e-01,  8.5938e-01, -1.8665e+00, -2.0821e-01, -7.7424e-02,\n",
      "          1.6272e-01, -3.0330e-01,  7.0038e-01, -1.2737e+00, -1.5919e+00,\n",
      "         -7.7144e-01,  8.0485e-01, -1.2085e+00, -3.0667e-01, -1.5735e+00,\n",
      "         -8.5166e-02,  8.3609e-01, -4.8414e-01,  4.4590e-01, -1.6653e-03,\n",
      "          4.1942e-01,  9.0515e-01, -5.5988e-01,  1.6246e-01,  1.9724e-01,\n",
      "          6.2806e-02, -1.0541e+00, -8.9015e-01,  1.2193e+00,  2.9977e-01,\n",
      "          1.5492e+00, -1.5566e+00, -1.1505e+00,  2.0593e-01, -1.9873e+00,\n",
      "         -2.5752e-01, -1.8356e-01, -7.5234e-01,  1.4487e+00, -9.1259e-01,\n",
      "         -4.5456e-01,  4.8068e-01,  1.1074e+00, -9.6042e-01,  2.8216e-02,\n",
      "          8.2695e-01, -5.3170e-01, -5.2691e-02],\n",
      "        [-8.4304e-02,  4.5664e-02,  1.2401e+00,  8.6788e-01, -4.1613e-01,\n",
      "         -2.2605e-01,  4.1408e-02, -1.6487e-01, -9.1978e-01, -1.2074e+00,\n",
      "          4.4864e-01, -1.3769e+00,  7.2494e-01, -4.2939e-01,  4.7911e-01,\n",
      "         -2.3169e-01, -1.7206e+00,  5.1571e-01,  9.1186e-01,  3.7110e-01,\n",
      "          7.1544e-01, -4.1825e-01,  5.2698e-01, -1.8224e-01, -7.9839e-01,\n",
      "          1.3637e+00,  7.9104e-01,  1.4324e+00, -8.8782e-02,  1.6795e+00,\n",
      "          9.7756e-01, -3.6656e-01,  1.1662e+00, -5.4374e-02,  1.5931e-01,\n",
      "         -2.5007e+00, -5.5757e-01,  1.1595e+00, -5.1505e-01,  1.6264e-01,\n",
      "          2.0056e+00, -2.3693e+00, -1.6360e-02, -8.8648e-01, -3.7813e-01,\n",
      "          1.6098e+00, -6.3392e-01, -6.7372e-01, -5.1844e-01,  1.0133e+00,\n",
      "         -5.8905e-01, -7.7268e-01,  5.5263e-01,  3.8386e-02,  2.1169e+00,\n",
      "          1.0047e-01,  4.3429e-01, -2.8386e-01, -4.9454e-02, -3.7125e-01,\n",
      "         -6.5128e-02, -1.3295e+00, -9.8861e-01, -1.0962e+00, -8.7985e-01,\n",
      "         -5.2142e-01, -4.6601e-02,  8.4147e-01, -2.9868e-01,  1.6483e+00,\n",
      "          5.7728e-01,  1.2138e+00,  3.8679e-01,  5.8493e-01,  3.6573e-01,\n",
      "          6.8986e-01,  4.3340e-01,  1.3122e+00, -5.2623e-01, -4.7031e-01,\n",
      "          7.3042e-01,  1.0908e+00, -1.6367e+00,  7.6432e-02,  3.7574e-01,\n",
      "          3.4590e-01, -4.7654e-01,  6.4432e-01, -9.4368e-01, -1.3694e+00,\n",
      "         -5.1158e-01,  1.0595e+00, -9.9254e-01, -6.8114e-01, -1.8525e+00,\n",
      "          1.0556e-02,  9.4936e-01, -2.2961e-01,  3.7854e-01, -6.1749e-02,\n",
      "          9.3876e-01,  6.7093e-01, -9.9162e-01,  5.9596e-01,  2.7523e-01,\n",
      "         -6.2721e-01, -1.0475e+00, -1.1740e+00,  6.3298e-01,  3.3131e-01,\n",
      "          1.7199e+00, -1.5693e+00, -8.9661e-01,  1.3004e-02, -2.1001e+00,\n",
      "         -4.5055e-01, -1.6542e-01, -1.0118e+00,  1.5739e+00, -2.8199e-01,\n",
      "         -9.6799e-01,  5.2082e-01,  1.3992e+00, -5.2616e-01,  2.6025e-03,\n",
      "          8.6469e-01, -2.1830e-01, -9.8221e-02],\n",
      "        [-5.2821e-01,  3.0536e-01,  1.1124e+00,  7.0770e-01, -4.9378e-01,\n",
      "          4.5625e-03, -2.7488e-01, -4.2648e-01, -6.1498e-01, -9.9059e-01,\n",
      "         -2.7969e-01, -1.4532e+00,  5.2734e-01, -8.3343e-01,  5.1560e-01,\n",
      "         -2.9854e-03, -1.7148e+00,  5.4506e-01,  7.0927e-01,  8.9734e-01,\n",
      "          5.5812e-01, -1.6418e-01, -5.2886e-01, -1.2300e-01, -7.6623e-01,\n",
      "          1.1092e+00,  6.6965e-01,  1.1441e+00, -2.8607e-01,  1.2381e+00,\n",
      "          1.1584e+00, -3.9656e-01,  1.3989e+00,  9.4925e-02,  5.5532e-01,\n",
      "         -2.5602e+00, -1.7962e-01,  1.0035e+00, -6.5906e-01,  1.8583e-01,\n",
      "          2.2937e+00, -2.1657e+00, -4.3113e-01, -7.3536e-01, -1.8349e-01,\n",
      "          2.4570e+00, -5.6072e-01,  3.0494e-02, -2.5186e-01,  7.3975e-01,\n",
      "         -5.3771e-01, -8.2609e-01,  8.1194e-01,  1.1098e-01,  1.9340e+00,\n",
      "         -1.4635e-01, -3.1135e-01,  8.7042e-02, -1.5846e-02, -4.8375e-01,\n",
      "         -3.0537e-01, -1.3350e+00, -1.1284e+00, -1.2208e+00, -7.3737e-02,\n",
      "         -3.4918e-01,  8.1143e-02,  4.3876e-01,  7.6928e-02,  1.4861e+00,\n",
      "          2.0004e-01,  1.2109e+00,  4.7898e-01,  5.0046e-01,  6.3884e-01,\n",
      "          4.8595e-01,  6.2977e-01,  8.3114e-01, -3.0148e-01, -2.7826e-02,\n",
      "          6.7400e-01,  9.2109e-01, -1.3763e+00,  8.6497e-02,  1.4758e-01,\n",
      "          4.9595e-01, -2.2731e-01,  6.7851e-01, -1.0166e+00, -1.4417e+00,\n",
      "         -7.9182e-01,  8.7683e-01, -1.1418e+00, -1.0083e+00, -1.6367e+00,\n",
      "         -2.3875e-01,  7.9048e-01, -6.5750e-01,  5.0342e-01, -2.0463e-01,\n",
      "          8.6895e-01,  3.8079e-01, -7.3243e-01,  9.5340e-02,  4.1317e-01,\n",
      "         -1.6903e-02, -8.8573e-01, -8.2969e-01,  7.9892e-01,  4.3205e-01,\n",
      "          1.6902e+00, -1.4322e+00, -1.3364e+00, -1.0671e-02, -1.9623e+00,\n",
      "         -8.1492e-02,  6.4160e-02, -5.0501e-01,  1.5712e+00, -5.4628e-01,\n",
      "         -3.6608e-01,  6.4943e-01,  1.3868e+00, -9.5952e-01,  2.6272e-01,\n",
      "          8.4626e-01, -2.7104e-01, -2.5378e-01],\n",
      "        [-4.5950e-01,  2.8391e-01,  1.3840e+00,  7.9456e-01, -4.2818e-01,\n",
      "         -4.2684e-01, -1.6967e-01, -3.4025e-01, -4.3838e-01, -1.0315e+00,\n",
      "          3.6662e-01, -1.2411e+00,  6.8702e-01, -4.1460e-01,  6.4811e-01,\n",
      "         -2.4053e-01, -1.6661e+00,  2.2680e-01,  7.2591e-01,  1.4771e-01,\n",
      "          5.4888e-01, -4.8462e-01,  4.0725e-01, -1.4053e-01, -7.7563e-01,\n",
      "          1.0197e+00,  4.8515e-01,  1.4326e+00, -1.0152e-01,  1.5496e+00,\n",
      "          8.0860e-01, -2.6539e-01,  1.1339e+00,  2.0625e-01,  4.3593e-01,\n",
      "         -3.0597e+00, -1.9431e-01,  1.3689e+00, -2.0914e-01, -1.3885e-02,\n",
      "          1.9814e+00, -1.9595e+00, -2.3043e-02, -5.8242e-01,  1.5391e-01,\n",
      "          1.8381e+00, -6.7966e-01, -1.7021e-01, -2.1871e-01,  1.1379e+00,\n",
      "         -5.6984e-01, -7.1573e-01,  8.5554e-01,  3.8666e-01,  1.9617e+00,\n",
      "         -1.1795e-01, -5.5115e-01, -2.3769e-01,  2.4939e-01, -4.8810e-02,\n",
      "         -7.8699e-01, -1.3148e+00, -9.1518e-01, -1.2017e+00, -6.7226e-01,\n",
      "         -4.4091e-02, -2.5686e-01,  8.6809e-01, -3.5145e-01,  1.3076e+00,\n",
      "          7.7203e-02,  1.0045e+00,  3.5548e-01,  8.0804e-01,  9.2702e-01,\n",
      "         -1.6542e-02,  3.0108e-01,  1.3479e+00, -2.4251e-01, -4.8139e-03,\n",
      "          7.1903e-01,  9.0304e-01, -1.5260e+00, -8.4793e-02,  4.2001e-01,\n",
      "          3.0938e-01, -5.3295e-01,  6.7880e-01, -1.5186e+00, -1.5814e+00,\n",
      "         -9.0021e-01,  9.2983e-01, -8.7990e-01, -8.1178e-01, -1.7893e+00,\n",
      "         -7.0853e-02,  9.9330e-01, -3.4421e-02,  2.8993e-01,  1.8384e-02,\n",
      "          1.2129e+00,  4.9856e-01, -7.3994e-01,  4.8097e-02,  4.7750e-01,\n",
      "         -2.4793e-01, -9.5965e-01, -6.7841e-01,  9.6468e-01,  5.8553e-01,\n",
      "          1.5348e+00, -1.8192e+00, -1.3886e+00, -3.3174e-01, -2.2055e+00,\n",
      "         -3.3337e-01, -2.8667e-01, -4.2769e-01,  1.5145e+00, -1.2214e-01,\n",
      "         -8.7928e-01,  6.1680e-01,  1.5959e+00, -5.9835e-01,  4.2592e-02,\n",
      "          1.6720e-01, -5.0130e-01,  2.8949e-01]], grad_fn=<MeanBackward1>)\n",
      "DEBUG:root:OutfitCompatibilityModel - outfit_score: torch.Size([5])\n",
      "DEBUG:root:OutfitCompatibilityModel - END\n",
      "DEBUG:root:!!!!!!!!!!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phamm\\MachineLearning_Playground\\outfit_recommendation\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images, texts)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m focal_loss(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     outputs, labels\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )  \u001b[39m# Ensure labels have the right dimension\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/MachineLearning_Playground/outfit_recommendation/main.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torch\\nn\\modules\\loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39;49m, target,\n\u001b[0;32m    726\u001b[0m                                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    727\u001b[0m                                               pos_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_weight,\n\u001b[0;32m    728\u001b[0m                                               reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\phamm\\.conda\\envs\\outfit_recommendation\\lib\\site-packages\\torch\\nn\\functional.py:3195\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[0;32m   3193\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTarget size (\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m) must be the same as input size (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 3195\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39;49m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in real_dataloader:\n",
    "        images = batch[\"outfit_images\"]\n",
    "        texts = batch[\"outfit_texts\"]\n",
    "        labels = batch[\"outfit_labels\"]\n",
    "\n",
    "        print(f\"batch - images.shape: {images.shape}\")\n",
    "        print(f\"batch - texts: {texts}\")\n",
    "        print(f\"batch - labels: {labels}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, texts)\n",
    "        loss = focal_loss(\n",
    "            outputs, labels\n",
    "        )  # Ensure labels have the right dimension\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print or log the loss if needed\n",
    "        print(f\"Epoch {epoch + 1}, Batch loss: {loss.item()}\")\n",
    "\n",
    "    save_checkpoint(model.state_dict(), \"mock\", f\"model_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "    # Adjust the learning rate as needed (reduce by half in steps of 10)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = param_group[\"lr\"] / 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "outfit_recommendation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
